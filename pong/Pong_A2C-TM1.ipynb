{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary software libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "from utils import test_policy_network, seed_everything, plot_stats\n",
    "from parallel_env import ParallelEnv, ParallelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import ROM from the extracted file to atari_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym 0.20+\n",
    "# from ale_py import ALEInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym 0.20+\n",
    "# ale = ALEInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym 0.20+\n",
    "# ! ale-import-roms /opt/anaconda3/envs/pongA2C/lib/python3.8/site-packages/ale_py/roms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run only once when creating conda environment\n",
    "! python -m atari_py.import_roms /Users/meng/Downloads/Roms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym 0.20+\n",
    "# from ale_py.roms import Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym 0.20+\n",
    "# ale.loadROM(Pong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to run?\n",
    "import atari_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyglet==1.5.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Pong-v4'\n",
    "#env_name = 'Acrobot-v1'\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "input_space = env.observation_space.shape\n",
    "\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dimensions: (210, 160, 3). Actions: 6\n",
      "Sample state: [[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"State dimensions: {input_space}. Actions: {actions}\")\n",
    "print(f\"Sample state: {env.reset()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_space[0] = 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"state_space[0] = {input_space[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcbb3480490>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.real(env.render(mode='rgb_array')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def __init__(self, env_name, obs_shape=(1, 64, 64)):\n",
    "        self.env = gym.make(env_name)\n",
    "        self.obs_shape = obs_shape\n",
    "        seed_everything(self.env)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        obs = self.preprocess_observation(obs)\n",
    "        return obs\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        actions = actions.squeeze().numpy()\n",
    "        self.env.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        obs, reward, done, info = self.env.step_wait()\n",
    "        obs = self.preprocess_observation(obs)\n",
    "        reward = torch.tensor(reward).unsqueeze(1).float()\n",
    "        done = torch.tensor(done).unsqueeze(1)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def preprocess_observation(self, obs):\n",
    "        # selecting the row from 35 to 195 so that we have a space of 160 * 160\n",
    "        obs = obs[35:195, :, :]\n",
    "        # change to gray scale\n",
    "        #obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "        # resize to \n",
    "        #obs = cv2.resize(obs, (self.obs_shape[1], self.obs_shape[2]), interpolation=cv2.INTER_AREA)\n",
    "        #obs = obs.astype(np.float32) / 255.0\n",
    "        #obs = torch.from_numpy(obs).unsqueeze(0)\n",
    "        return obs\n",
    "    \n",
    "    \"\"\"\n",
    "    def render(self, obs):\n",
    "        # try to show the image after resize but doesn't support\n",
    "        \n",
    "        obs = obs[35:195, :, :]\n",
    "        # change to gray scale\n",
    "        obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "        # resize to \n",
    "        obs = cv2.resize(obs, (self.obs_shape[1], self.obs_shape[2]), interpolation=cv2.INTER_AREA)\n",
    "        obs = obs.astype(np.float32) / 255.0\n",
    "        \n",
    "        plt.imshow(np.real(obs.render(mode='rgb_array'))\n",
    "        \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessEnv(ParallelWrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.venv.reset()\n",
    "        return torch.from_numpy(state).float()\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        actions = actions.squeeze().numpy()\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        next_state, reward, done, info = self.venv.step_wait()\n",
    "        next_state = torch.from_numpy(next_state).float()\n",
    "        reward = torch.tensor(reward).unsqueeze(1).float()\n",
    "        done = torch.tensor(done).unsqueeze(1)\n",
    "        return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*4*4, 512)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = x.view(-1, 64*4*4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, n_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=64*4*4, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=521, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc5 = nn.Linear(in_features=64, out_features=n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=64*4*4, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=521, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc5 = nn.Linear(in_features=64, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic():\n",
    "    def __init__(self, actor, critic, feature_extractor, alpha=1e-4, gamma=0.99):\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.actor_optim = AdamW(self.actor.parameters(), lr=1e-3)\n",
    "        self.critic_optim = AdamW(self.critic.parameters(), lr=1e-4)\n",
    "        self.stats = {'Actor Loss': [], 'Critic Loss': [], 'Returns': []}\n",
    "\n",
    "    def train(self, env, episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        for episode in tqdm(range(1, episodes + 1)):\n",
    "            state = env.reset()\n",
    "            done_b = torch.zeros((env.num_envs, 1), dtype=torch.bool)\n",
    "            ep_return = torch.zeros((env.num_envs, 1))\n",
    "            I = 1.\n",
    "\n",
    "            while not done_b.all():\n",
    "                \n",
    "                feature = feature_extractor(state)\n",
    "                probs = self.actor(feature)\n",
    "                #probs = self.actor(state)\n",
    "                \n",
    "                #action = self.actor(state).multinomial(1).detach()\n",
    "                action = torch.multinomial(probs, 1).squeeze().detach()\n",
    "                \n",
    "\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                value = self.critic(feature)\n",
    "                #value = self.critic(state)\n",
    "                \n",
    "                feature_next_state = feature(next_state)\n",
    "                \n",
    "                target = reward + ~done * self.gamma * self.critic(feature_next_state).detach() #\n",
    "                critic_loss = nn.functional.mse_loss(value, target)\n",
    "                self.critic_optim.zero_grad()\n",
    "                critic_loss.backward()\n",
    "                self.critic_optim.step()\n",
    "\n",
    "\n",
    "                advantage = (target - value).detach()\n",
    "                #probs = self.actor(state)\n",
    "                log_probs = torch.log(probs + 1e-6)\n",
    "                \n",
    "                action = action.view(-1, 1)\n",
    "                action_log_prob = log_probs.gather(1, action)\n",
    "                \n",
    "                \n",
    "                action_log_prob = log_probs.gather(1, action)\n",
    "                entropy = - torch.sum(probs * log_probs, dim=-1, keepdim=True)\n",
    "                actor_loss = - I * action_log_prob * advantage - 0.01 * entropy\n",
    "                actor_loss = actor_loss.mean()\n",
    "                self.actor_optim.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optim.step()\n",
    "\n",
    "                ep_return += reward\n",
    "                done_b |= done\n",
    "                state = next_state\n",
    "                I = I * self.gamma\n",
    "\n",
    "            self.stats['Actor Loss'].append(actor_loss.item())\n",
    "            self.stats['Critic Loss'].append(critic_loss.item())\n",
    "            self.stats['Returns'].append(ep_return.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Pong-v4'\n",
    "num_envs = os.cpu_count()\n",
    "episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'observation_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m envs \u001b[38;5;241m=\u001b[39m \u001b[43mParallelEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m envs \u001b[38;5;241m=\u001b[39m PreprocessEnv(envs)\n",
      "File \u001b[0;32m~/Documents/semester8/Thesis/workspace/pong_and_a2c/parallel_env.py:172\u001b[0m, in \u001b[0;36mParallelEnv.__init__\u001b[0;34m(self, env_fns, spaces, context)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m env_fns[\u001b[38;5;241m0\u001b[39m]()\n\u001b[0;32m--> 172\u001b[0m     observation_space, action_space \u001b[38;5;241m=\u001b[39m \u001b[43mdummy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m, dummy\u001b[38;5;241m.\u001b[39maction_space\n\u001b[1;32m    173\u001b[0m     dummy\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m dummy\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'observation_space'"
     ]
    }
   ],
   "source": [
    "envs = ParallelEnv([lambda: Environment(env_name).reset() for _ in range(num_envs)])\n",
    "envs = PreprocessEnv(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(envs.observation_space.shape)\n",
    "actor = Actor(envs.action_space.n)\n",
    "critic = Critic()\n",
    "agent = ActorCritic(actor, critic, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                     | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 3, 3], expected input[8, 210, 160, 3] to have 1 channels, but got 210 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mActorCritic.train\u001b[0;34m(self, env, episodes)\u001b[0m\n\u001b[1;32m     17\u001b[0m I \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done_b\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 22\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(feature)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#probs = self.actor(state)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#action = self.actor(state).multinomial(1).detach()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pongA2C/lib/python3.8/site-packages/torch/nn/modules/module.py:722\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    724\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    726\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mFeatureExtractor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pongA2C/lib/python3.8/site-packages/torch/nn/modules/module.py:722\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    724\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    726\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pongA2C/lib/python3.8/site-packages/torch/nn/modules/conv.py:419\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pongA2C/lib/python3.8/site-packages/torch/nn/modules/conv.py:415\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    413\u001b[0m                     weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    414\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 1, 3, 3], expected input[8, 210, 160, 3] to have 1 channels, but got 210 channels instead"
     ]
    }
   ],
   "source": [
    "agent.train(envs, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(agent.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy_network(env, agent.actor, episodes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " [[109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  ...\n",
      "  [109 118  43]\n",
      "  [109 118  43]\n",
      "  [109 118  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]\n",
      "\n",
      " [[ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  ...\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]\n",
      "  [ 53  95  24]]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Environment object at 0x7fcbb35d70d0>\n"
     ]
    }
   ],
   "source": [
    "env = Environment(env_name)\n",
    "obs = env.reset()\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 210, 160, 3])\n"
     ]
    }
   ],
   "source": [
    "obs = envs.reset()\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "envs = ParallelEnv([lambda: Environment(env_name).env for _ in range(num_envs)])\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #def plot_stats(self):\n",
    "    #    plt.plot(self.stats['Actor Loss'], label='Actor Loss')\n",
    "    #    plt.plot(self.stats['Critic Loss'], label='Critic Loss')\n",
    "    #    plt.plot(self.stats['Returns'], label='Returns')\n",
    "    #    plt.legend()\n",
    "    #    plt.show()\n",
    "\n",
    "    #def test_policy_network(self, env, episodes=2):\n",
    "    #    with torch.no_grad():\n",
    "    #        for episode in range(episodes):\n",
    "    #            state = env.reset()\n",
    "    #            done = False\n",
    "    #            total_reward = 0\n",
    "\n",
    "    #            while not done:\n",
    "    #                action = self.actor(state).argmax(dim=1).detach()\n",
    "    #                next_state, reward, done, _ = env.step(action)\n",
    "    #                total_reward += reward\n",
    "    #                state = next_state\n",
    "\n",
    "    #            print(f'Episode {episode+1}: Total reward = {total_reward.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
